---
title: "ST558_2024_Project2"
format: html
editor: visual
---

# Melbourne Housing Market Data

Welcome to the beach city of Melbourne, Australia! For this project let's take a look at the interesting housing market data. I chose this data set because data contains the date data, which is really good for visulization using an Rshiny App!

I have downloaded the Melbourne housing data from \[here\] (http://www.kaggle.com/datasets/anthonypino/melbourne-housing-market): . Let's first import data and make some summaries.

```{r}
library (dplyr) 
library (tidyverse) 
library (ggplot2)
library (gridExtra)
library (pheatmap)
setwd ("C:/NCSU/Statistics/ST558/2024/ST558_2024-Project 2")  
MelHousing <- read.csv ("MELBOURNE_HOUSE_PRICES.csv") |> as.tibble () 
MelHousing 
str(MelHousing)
```

## Data summary

### Categorical summaries

From the function str(), we could see the data set has about 63k records of housing, with 13 variables. There are 8 categorical variables and 5 quantitative variables. For the categorical variables, some are very interesting. For example, the variable "Regionname" indicates which region a specific housing is seated in, the "Type" variable showed the type of housing.

```{r}
MelHousing <- MelHousing |> mutate (RegionF = as.factor (Regionname),
                      TypeF = factor (Type, 
                                      levels = c ("h", "t", "u"),
                                      labels = c ("house", "townhouse","duplex")))

MelHousing |> group_by(RegionF) |> drop_na (RegionF) |> summarize (count = n())

MelHousing |> group_by(TypeF) |> drop_na (TypeF) |> summarize (count = n())
```

So there are 8 different city area in Melbourn. Among those different regions, the Southern Metropolitan and the Northern Metropolitan clearly had the most number of housing options and there are three different types of housing: house (h), townhouse (t) and duplex (u). How about making a two-way contingency table?

```{r}
MelHousing |> group_by (RegionF, TypeF) |> drop_na (RegionF, TypeF) |> summarize (count = n()) |> pivot_wider (names_from = RegionF, values_from = count) |> as.data.frame()
```

This table lists the number of different types of housing in different district. It is interesting to see not only the number of housing, but how different areas of a city tend to favor a certain type of housing instead of other types. For example the ratio between house and duplex is close to 7:1 in the Eastern metro region, but is close to 2:1 in the southern metro region. The housing type (and probably density) between those two regions must be very different.

```{r}
MelHousing <- MelHousing |> mutate (RoomsF = as.factor (Rooms))
MelHousing |> group_by(RoomsF) |> drop_na (RoomsF) |> summarize (count = n())
MelHousing |> group_by (RegionF, RoomsF) |> drop_na (RegionF, RoomsF) |> summarize (count = n()) |> pivot_wider (names_from = RegionF, values_from = count) |> as.data.frame()
```

The variable "rooms" is a quantitative one, but we could anyway coerce So if we make a 2-way contigency table on "Region" and "Rooms" same thing could be observed here: Dueling units with 1 room only are very rare in the Eastern Metro region (less than 1%), while it constitutes quite a fraction (about 7%) in the Southern Metropolitan region.

### Numeric summaries

There are five numeric variables: "Rooms", "Price", "Postcode", "Property count" and "Distance", while Postcode is not a real "quantitative" variable. Let's make a summary first on the rest four variables.

```{r}
MelHousingnum <- MelHousing |> select (Rooms, Price, Propertycount, Distance)
summary (MelHousingnum)
```

It is interesting to see the housing price in different city regions, we could make a data summary on this accordingly.

```{r}
MelHousing |> group_by(RegionF) |> drop_na (Price) |>
  summarize (across(Price,
             .fns = list ("Mean" = mean,
                          "Median" = median,
                          "Variation" = var,
                          "IQR" = IQR)))
```

To see the distribution of those four variables, including the number of rooms in a house, the price of the house, the property counts of the Suburbs and the houses' distance from Melbourn CBD, we could make four density plot and put them together.

```{r}
roomsp <- ggplot (MelHousingnum, aes (x = Rooms)) +
  geom_histogram(color = "black", fill = "skyblue", alpha = 0.5) +
  labs (x = "Rooms")
pricep <- ggplot (MelHousingnum, aes (x = Price)) +
  geom_histogram(color = "black", fill = "lightgreen", alpha = 0.5) +
  labs (x = "Price")
propertycountp <- ggplot (MelHousingnum, aes (x = Propertycount)) +
  geom_histogram(color = "black", fill = "pink", alpha = 0.5) +
  labs (x = "Property count")
Distancep <- ggplot (MelHousingnum, aes (x = Distance)) +
  geom_histogram(color = "black", fill = "lightyellow", alpha = 0.5) +
  labs (x = "Distance from CBD")
grid.arrange(roomsp, pricep, propertycountp, Distancep, ncol = 2)
```

They all look like gamma distribution with different shape and scale paramaters.

Since the dataset has a date data, let's pick it up and plot a time-series plot on those numeric variables. So it is basically a line plot

```{r}
MelHousing$Date <- as.Date (MelHousing$Date, format = "%m/%d/%Y")
daily_avg_price <- MelHousing |> group_by(Date) |> summarize (price_avg = mean (Price, na.rm = TRUE))
ggplot (daily_avg_price, aes (x = Date, y = price_avg)) +
  geom_line (color = "black") +
  labs (title = "Average Housing Price Over Time", x = "Date", y = "Average Melbourne Housing price")
```

There is no significant trend in the average price throughout the years. Meanwhile we could plot the same time-plot based on different Region in Melbourne.

```{r}
daily_avg_price <- MelHousing |> group_by(Date, RegionF) |> 
  summarize (price_avg = mean (Price, na.rm = TRUE))

ggplot (daily_avg_price, aes (x = Date, y = price_avg, color = RegionF)) +
  geom_line (size = 0.7) +
  labs (title = "Housing Price Over Time by different regions", 
        x= "Date", 
        y = "Average Melbourne Housing price",
        color = "Region")
```

It would be also very interesting to look at the interplay between housing price and the distance to CBD. Use ggplot to plot the dot plot using x = "Distance" and y = "Price". In addtion, we could use rooms as a factor to make a facet grid. Note most of the housing units have room number less than or equal to 6

```{r}
MelHousing_room6 <- MelHousing |> filter (Rooms <= 6)

ggplot (MelHousing_room6, aes (x = Distance, y = Price)) +
  geom_point (color = "purple", alpha = 0.5, size = 0.5) +
  labs (x = "Distance to CBD", y = "Housing price") +
  facet_wrap(~Rooms)
```

We could see no matter how many rooms, the peak housing price comes at about somewhere around 5 miles to CBD. For this we could add another dimension of facet using facet_grid function.

```{r}
MelHousing_room6_metro <- MelHousing_room6 |> filter (grepl ("Metropolitan", Regionname)) |> filter (!grepl ("South-Eastern",Regionname))

ggplot (MelHousing_room6_metro, aes (x = Distance, y = Price)) +
  geom_point (color = "goldenrod", alpha = 0.5, size = 0.5) +
  labs (x = "Distance to CBD", y = "Housing price") +
  facet_grid(RegionF~Rooms)
```

It is interesting to see although the housing price in the Eastern and Southern metropolitan areas were similar among housing units with 1-3 bedrooms, southern metro neighbourhoods are much pricier at 4-6 bedroom houses. In fact there is a single house in the south metropolitan area that tops all the prices, which is a 4 bedroom house.

#### Heatmap for daily price for different region

It is interesting to look at the price changes of housing in different region at different time points. To make a heatmap meaningful, we first need to sort out the average price data for each council area at each time point, and then do normalization.

```{r}
daily_avg_price_regionF <- MelHousing |> group_by(Date, RegionF) |> 
  summarize (price_avg = mean (Price, na.rm = TRUE)) |>
  pivot_wider(names_from = RegionF, values_from = price_avg) |>
  drop_na()
daily_avg_price_regionF

```

Then we need to normalize the data using the function mutate (across(everything(), \~./first (.)))

```{r}
first_values <- sapply(daily_avg_price_regionF[-1], first)

daily_avg_price_regionF_normalized <- daily_avg_price_regionF |>
  mutate (across (everything(), ~. / first_values[cur_column()]))
  
daily_avg_price_regionF_normalized
```

Now you could see the housing price has been normalized according to the first value of each column to reflect their relative changes. I will continue using the pheatmap () function.

```{r}
DAPRN_heatmap <- daily_avg_price_regionF_normalized |> column_to_rownames(var = "Date")

pheatmap (DAPRN_heatmap,
          cluster_rows = FALSE,
          treeheight_col = 20,
          color = colorRampPalette(c("blue", "white", "red"))(50),
          main = "Housing Price Heatmap",
          cellwidth = 16,
          cellheight = 8,
          angle_col = 45)
```

From this heatmap you could roughly see housing price actually followed different trending at different areas. Now make an App to enable end users to visualize our data set!
